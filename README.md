## 1 Introduction to Deep Learning

### Text Book

1. Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. **Deep learning**. An MIT Press book. (2015). [pdf](https://github.com/HFTrader/DeepLearningBook/raw/master/DeepLearningBook.pdf)

### High-level Survey

2. LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. **Deep learning**. Nature 521.7553 (2015): 436-444.[pdf](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)
   ️️️️️

### Courses

3. MIT 6.S191Introduction to Deep Learning [web](http://introtodeeplearning.com/)
4. Dive into Deep Learning [web](https://d2l.ai/index.html)

## 2 Convolutional Neural Networks (CNNs)

### LeNet: Image Classification on Handwritten Digits and Image Classification on ImageNet

1. Y. LeCun, L. Bottou, Y. Bengio and P. Haffner. **Gradient-Based Learning Applied to Document Recognition.**  Proceedings of the IEEE, 86(11):2278-2324. 1998. [pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) (Seminal Paper: LeNet)
2. Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. **Imagenet classification with deep convolutional neural networks**. Advances in neural information processing systems. 2012. [pdf](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
3. Simonyan, Karen, and Andrew Zisserman. **Very deep convolutional networks for large-scale image recognition**. arXiv preprint arXiv:1409.1556 (2014). [pdf](https://arxiv.org/pdf/1409.1556.pdf)
4. Szegedy, Christian, et al. **Going deeper with convolutions**. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)
5. He, Kaiming, et al. **Deep residual learning for image recognition**. arXiv preprint arXiv:1512.03385 (2015). [pdf](https://arxiv.org/pdf/1512.03385.pdf) [ResNet](https://arxiv.org/pdf/1512.03385.pdf)
6. Huang, G. et al. **Densely Connected Convolutional Networks**. arXiv preprint arXiv:1608.06993 (2017) [pdf](https://arxiv.org/pdf/1608.06993.pdf) (DenseNet)
7. Hu, Jie et al.  **Squeeze-and-Excitation Networks**. arXiv preprint arXiv:1709.01507 (2017) [pdf](https://arxiv.org/pdf/1709.01507.pdf)
8. Howard, A. G. et al. **MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications.** [pdf](https://arxiv.org/abs/1704.04861)\]
9. Tan, M. and Le, Q. V. **EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks**. [pdf](https://arxiv.org/abs/1905.11946)
10. Xie, Q. et al. **Self-training with Noisy Student improves ImageNet classification.** [pdf](https://arxiv.org/pdf/1911.04252.pdf)
11. Bojarski, M. et al. **End to End Learning for Self-Driving Cars.** [pdf](https://arxiv.org/pdf/1604.07316.pdf)

## 3 Object Detection

1. H. A. Rowley, S. Baluja, and T. Kanade, **Neural network-based face detection,** Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognition, pp. 203–208, 1996. [pdf](https://courses.cs.washington.edu/courses/cse577/05sp/papers/rowley.pdf)
2. P. Viola and M. Jones, **Rapid object detection using a boosted cascade of simple features,** in Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. [pdf](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)
3. Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. **Deep neural networks for object detection.** Advances in Neural Information Processing Systems. 2013. [pdf](http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf)
4. Girshick, Ross, et al. **Rich feature hierarchies for accurate object detection and semantic segmentation**. Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf) RCNN
5. He, Kaiming, et al. **Spatial pyramid pooling in deep convolutional networks for visual recognition**. European Conference on Computer Vision. Springer International Publishing, 2014. [pdf](http://arxiv.org/pdf/1406.4729) SPPNet
6. Girshick, Ross. **Fast r-cnn**. Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf)️️️️
7. Ren, Shaoqing, et al. **Faster R-CNN: Towards real-time object detection with region proposal networks**. Advances in neural information processing systems. 2015. [pdf](https://arxiv.org/abs/1506.01497) ️️️️
8. Redmon, Joseph, et al. **You only look once: Unified, real-time object detection**. arXiv preprint arXiv:1506.02640 (2015).[pdf](http://homes.cs.washington.edu/~ali/papers/YOLO.pdf)
9. Liu, Wei, et al. **SSD: Single Shot MultiBox Detector**. arXiv preprint arXiv:1512.02325 (2015). [pdf](http://arxiv.org/pdf/1512.02325)
10. Dai, Jifeng, et al. **R-FCN: Object Detection via Region-based Fully Convolutional Networks**. arXiv preprint arXiv:1605.06409 (2016).[pdf](https://arxiv.org/abs/1605.06409)
11. K. He et al. **Mask R-CNN** arXiv preprint arXiv:1703.06870 (2017). [pdf](https://arxiv.org/abs/1703.06870)
12. Tsung-Yi Lin et al. **Feature Pyramid Networks for Object Detection.** arXiv:1612.03144 (2017). [pdf](https://arxiv.org/pdf/1612.03144.pdf)
13. Esteban Real, Alok Aggarwal, Yanping Huang: **Regularized Evolution for Image Classifier Architecture Search**, 2018; arXiv:1802.01548 [pdf](https://arxiv.org/pdf/1802.01548.pdf)
14. Golnaz Ghiasi, Tsung-Yi Lin, Ruoming Pang: **NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection**, 2019; arXiv:1904.07392 [pdf](https://arxiv.org/pdf/1904.07392.pdf)
15. Chenchen Zhu, Yihui He: **Feature Selective Anchor-Free Module for Single-Shot Object Detection**, 2019; arXiv:1903.00621 [pdf](https://arxiv.org/pdf/1903.00621.pdf)
16. Yukang Chen, Tong Yang, Xiangyu Zhang, Gaofeng Meng, Xinyu Xiao: **DetNAS: Backbone Search for Object Detection**, 2019; arXiv:1903.10979 [pdf](https://arxiv.org/pdf/1903.10979.pdf)
17. Kaiwen Duan, Song Bai, Lingxi Xie, Honggang Qi, Qingming Huang: **CenterNet: Keypoint Triplets for Object Detection**, 2019; arXiv:1904.08189 [pdf](https://arxiv.org/pdf/1904.08189.pdf)
18. Mingxing Tan, Ruoming Pang: **EfficientDet: Scalable and Efficient Object Detection**, 2019; arXiv:1911.09070 [pdf](https://arxiv.org/pdf/1911.09070.pdf)

## 4 Object Segmentation and Self-Supervised Learning

**Segmentation:**

1. J. Long, E. Shelhamer, and T. Darrell, **Fully convolutional networks for semantic segmentation**. in CVPR, 2015. [pdf](https://arxiv.org/pdf/1411.4038v2.pdf)
2. O. Ronnenberger et al. **U-Net: Convolutional Networks for Biomedical Image Segmentation.** 2015. [pdf](https://arxiv.org/pdf/1505.04597.pdf)
3. **Multi-Scale Context Aggregation by Dilated Convolutions.** 2016. [pdf](https://arxiv.org/pdf/1511.07122.pdf)
4. **DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs.** 2016. [pdf](https://arxiv.org/pdf/1606.00915.pdf)
5. **Rethinking Atrous Convolution for Semantic Image Segmentation**. 2017.  [pdf](https://arxiv.org/pdf/1706.05587.pdf)
6. K. He et al. **Mask R-CNN** arXiv preprint arXiv:1703.06870. 2017. [pdf](https://arxiv.org/abs/1703.06870)
7. **Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation.** 2018. [pdf](https://arxiv.org/pdf/1802.02611.pdf)
8. **Learning to Segment Everything.** 2018. [pdf](https://arxiv.org/pdf/1711.10370.pdf)

**Self-Supervised Learning:**

1. **Unsupervised Visual Representation Learning by Context Prediction.** 2015. [pdf](https://arxiv.org/pdf/1505.05192.pdf)
2. **Colorful Image Colorization.** 2016. [pdf](https://arxiv.org/pdf/1603.08511.pdf)
3. **Representation Learning by Learning to Count**. 2017. [pdf](https://arxiv.org/pdf/1708.06734.pdf)
4. **Learning and Using the Arrow of Time.** 2018. [pdf](https://www.robots.ox.ac.uk/~vgg/publications/2018/Wei18/wei18.pdf)
5. **Tracking Emerges by Colorizing Videos.** 2018. [pdf](https://arxiv.org/pdf/1806.09594.pdf)
6. **Audio-Visual Scene Analysis with Self-Supervised Multi-sensory Features.** 2018. [pdf](https://arxiv.org/pdf/1804.03641.pdf)
7. **Object Discovery with a Copy-Pasting GAN.** 2019. [pdf](https://arxiv.org/pdf/1905.11369.pdf)
8. **SimCLR: A Simple Framework for Contrastive Learning of Representations.** 2020. [pdf](https://arxiv.org/pdf/2002.05709.pdf)

## 5 Generative Adversarial Networks and Applications

**Generative Adversarial Networks:**

1. Kingma, D, and Welling, M. **Auto-encoding variational bayes**. arXiv preprint arXiv:1312.6114 (2013). [pdf](http://arxiv.org/pdf/1312.6114)
2. Goodfellow, Ian, et al. **Generative adversarial nets**.  2014. [pdf](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)
3. Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. **Pixel recurrent neural networks**. arXiv preprint arXiv:1601.06759 (2016). [pdf](http://arxiv.org/pdf/1601.06759)
4. Makzhani, Alireza, et al. **Adversarial Autoencoders** arXiv:1511.05644 (2015). [pdf](https://arxiv.org/pdf/1511.05644)
5. Gregor, Karol, et al. **DRAW: A recurrent neural network for image generation**. arXiv:1502.04623 (2015). [pdf](http://jmlr.org/proceedings/papers/v37/gregor15.pdf)

**Applications:**

1. **Wasserstein GAN.**  2017. [pdf](https://arxiv.org/pdf/1701.07875.pdf)
2. **Large Scale GAN Training for High Fidelity Natural Image Synthesis.** 2018. [pdf](https://arxiv.org/pdf/1809.11096.pdf)
3. **A Style-based Generator Architecture for Generative Adversarial Networks** 2018. [pdf](https://arxiv.org/pdf/1812.04948.pdf)
4. **Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks** 2017. [pdf](https://arxiv.org/pdf/1703.10593.pdf)
5. **Conditional LSTM-GAN for Melody Generation from Lyrics.** 2019. [pdf](https://arxiv.org/pdf/1908.05551.pdf)
6. **GANFIT: Generative Adversarial Network Fitting for High Fidelity 3D Face Reconstruction.** 2019. [pdf](https://arxiv.org/pdf/1902.05978.pdf)

**Art:**

1. Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). **Inceptionism: Going Deeper into Neural Networks**. Google Research. [html](https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)
2. Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. **A neural algorithm of artistic style**. arXiv preprint arXiv:1508.06576 (2015). [pdf](http://arxiv.org/pdf/1508.06576)
3. **CAN: Creative Adversarial Networks** 2017. [pdf](https://arxiv.org/pdf/1706.07068.pdf)
4. **Semantic Image Synthesis with Spatially-Adaptive Normalization** 2019. [pdf](https://arxiv.org/pdf/1903.07291.pdf)
5. **Deep Poetry: Word-Level and Char-Level Language Models for Shakespearean Sonnet Generation** [pdf](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/reports/2762063.pdf)
6. **BachProp: Learning to Compose Music in Multiple Styles** 2018. [pdf](https://arxiv.org/pdf/1802.05162.pdf)
7. **A 'New' Rembrandt: From the Frontiers of AI And Not The Artist's Atelier** 2016. [html](https://www.npr.org/sections/alltechconsidered/2016/04/06/473265273/a-new-rembrandt-from-the-frontiers-of-ai-and-not-the-artists-atelier)
8. **Is artificial intelligence set to become art’s next medium?** 2018. [html](https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx)
9. **AI Will Enhance - Not End - Human Art** 2019. [html](https://onezero.medium.com/a-i-will-enhance-not-end-human-art-f575e9ff9325)
10. **An AI-Written Novella Almost Won a Literary Prize** 2016. [html](https://www.smithsonianmag.com/smart-news/ai-written-novella-almost-won-literary-prize-180958577/)
11. **How AI-Generated Music Is Changing The Way Hits Are Made** 2018.[html](https://www.theverge.com/2018/8/31/17777008/artificial-intelligence-taryn-southern-amper-music)
12. **AI puts final notes on Beethoven's Tenth Symphony** 2019. [html](https://techxplore.com/news/2019-12-ai-beethoven-tenth-symphony.html)

**Previous Papers**

1. Zhu, Jun-Yan, et al. **Generative Visual Manipulation on the Natural Image Manifold**. European Conference on Computer Vision. Springer International Publishing, 2016. [pdf](https://arxiv.org/pdf/1609.03552)
2. Champandard, Alex J. **Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks**. arXiv preprint arXiv:1603.01768 (2016). [pdf](http://arxiv.org/pdf/1603.01768)
3. Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. **Perceptual losses for real-time style transfer and super-resolution**. arXiv preprint arXiv:1603.08155 (2016). [pdf](https://arxiv.org/pdf/1603.08155.pdf) ️️️️
4. Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. **A learned representation for artistic style**. arXiv preprint arXiv:1610.07629 (2016). [pdf](https://arxiv.org/pdf/1610.07629v1.pdf) ️️️️
5. Gatys, Leon and Ecker, et al.**Controlling Perceptual Factors in Neural Style Transfer**. arXiv preprint arXiv:1611.07865 (2016). [pdf](https://arxiv.org/pdf/1611.07865.pdf)
6. Ulyanov, Dmitry and Lebedev, Vadim, et al. **Texture Networks: Feed-forward Synthesis of Textures and Stylized Images**. arXiv preprint arXiv:1603.03417(2016). [pdf](http://arxiv.org/abs/1603.03417)

## 6 RNN / Sequence-to-Sequence Model

1. Bengio, Yoshua et. al. **A Neural Probabilistic Model** JMLR (2003). [pdf](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)
2. Graves, Alex. **Generating sequences with recurrent neural networks**. arXiv preprint arXiv:1308.0850 (2013). (LSTM, very nice generating result, show the power of RNN) [pdf](http://arxiv.org/pdf/1308.0850)
3. Mikolov, et al. **Distributed representations of words and phrases and their compositionality**. NIPS(2013) [pdf](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
4. Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. **Sequence to sequence learning with neural networks**. Advances in neural information processing systems. 2014.[pdf](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)
5. Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. **Neural Machine Translation by Jointly Learning to Align and Translate**. (2014). [pdf](https://arxiv.org/pdf/1409.0473v7.pdf)

## 7 NLP (Natural Language Processing)

1. Ashish Vaswani, et al. **Attention is All you Need**. NIPS (2017) [pdf](https://arxiv.org/pdf/1706.03762.pdf)
2. Matthew Peters, et al. **Deep Contexualized Word Representations**. [pdf](https://arxiv.org/pdf/1802.05365.pdf)
3. Jeremy Howard, et al.  **Universal Language Model Fine-Tuning for Text Classification** ACL (2018) [pdf](https://arxiv.org/pdf/1801.06146.pdf)
4. 4. Jacob Devlin, et al. **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding** (2019) [pdf](https://arxiv.org/pdf/1810.04805.pdf)
5. 5. Victor Sanh, et al. **DistilBERT, a distilled version of BERT**. arXiv preprint arXiv:1910.01108(2019) [pdf](https://arxiv.org/pdf/1910.01108.pdf)

## 8 Machine Translation

1. Lee, et al. **Fully Character-Level Neural Machine Translation without Explicit Segmentation**. (2016) [pdf](https://arxiv.org/pdf/1610.03017.pdf)
2. Wu, Schuster, Chen, Le, et al. **Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation**. [pdf](https://arxiv.org/pdf/1609.08144v2.pdf)
3. Jonas Gehring, et al. **Convolutional Sequence to Sequence Learning**. (2017). [pdf](https://arxiv.org/pdf/1705.03122.pdf)
4. Lample, et al. **Phrase-Based & Neural Unsupervised Machine Translation**. (2018) [pdf](https://arxiv.org/pdf/1804.07755.pdf)
5. Ye Jia, et al. **Direct Speech-to-Speech Translation with a Sequence-to-Sequence Model**. (2019). [pdf](https://arxiv.org/pdf/1904.06037.pdf)

## 9 Applications of Sequence-to-Sequence Models

1. Wen, et al. **Recurrent Neural Network Language Generation for Spoken Dialogue Systems**. (2019) [pdf](https://www.sciencedirect.com/science/article/pii/S0885230817300578)
2. Mrksic, et al. **Multi-domain Dialog State Tracking using RNNs**. (2015) [pdf](https://arxiv.org/pdf/1506.07190.pdf)
3. Srinivasan, et al. **Natural Language Generation using Reinforcement Learning with External Rewards**. (2019). [pdf](https://arxiv.org/pdf/1911.11404.pdf)
4. Zhu, et al. **SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering**. (2018) [pdf](https://arxiv.org/pdf/1812.03593.pdf)
5. Xiong, et al. **Achieving Human Parity in Conversational Speech Recognition**. arXiv:1610.05256 (2016). [pdf](https://arxiv.org/pdf/1610.05256.pdf)

## 10 Reinforcement Learning

1. Mnih, Volodymyr, et al. **Playing atari with deep reinforcement learning**. (2013). [pdf](http://arxiv.org/pdf/1312.5602.pdf)
2. Silver, David, et al. **Mastering the game of Go with deep neural networks and tree search**. (2016) [pdf](https://www.nature.com/articles/nature16961.pdf)
3. Silver, David, et al. **Mastering the game of Go without Human Knowledge**. (2017) [pdf](http://augmentingcognition.com/assets/Silver2017a.pdf)
4. Silver, David, et al. **Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm**. (2017) [pdf](https://arxiv.org/pdf/1712.01815.pdf)
5. OpenAI. **Learning Dexterous In-Hand Manipulation**. [pdf](https://arxiv.org/pdf/1808.00177.pdf)

**Previous Papers**
1. Mnih, Volodymyr, et al. **Human-level control through deep reinforcement learning**. (2015) [pdf](https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf)
2. Wang, Ziyu, Nando de Freitas, and Marc Lanctot. **Dueling network architectures for deep reinforcement learning**. (2015). [pdf](http://arxiv.org/pdf/1511.06581)
3. Mnih, Volodymyr, et al. **Asynchronous methods for deep reinforcement learning**. (2016). [pdf](http://arxiv.org/pdf/1602.01783)
4. Lillicrap, Timothy P., et al. **Continuous control with deep reinforcement learning**. (2015). [pdf](http://arxiv.org/pdf/1509.02971)
5. Gu, Shixiang, et al. **Continuous Deep Q-Learning with Model-based Acceleration**. (2016). [pdf](http://arxiv.org/pdf/1603.00748)
6. Schulman, John, et al. **Trust region policy optimization**. CoRR, abs/1502.05477 (2015). [pdf](http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf)

## 11 Unsupervised Learning / Deep Generative Model

1. Le, Quoc V. **Building high-level features using large scale unsupervised learning**. [pdf](http://arxiv.org/pdf/1112.6209.pdf&embed)
2. Kingma, Diederik P., and Max Welling. **Auto-encoding variational bayes**. (2013). [pdf](http://arxiv.org/pdf/1312.6114)
3. Goodfellow, Ian, et al. **Generative adversarial nets**. Advances in Neural Information Processing Systems. 2014. [pdf](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)
4. Radford, Alec, Luke Metz, and Soumith Chintala. **Unsupervised representation learning with deep convolutional generative adversarial networks**. (2015). [pdf](http://arxiv.org/pdf/1511.06434)
5. Gregor, Karol, et al. **DRAW: A recurrent neural network for image generation**. (2015). [pdf](http://jmlr.org/proceedings/papers/v37/gregor15.pdf)
6. Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. **Pixel recurrent neural networks**. (2016). [pdf](http://arxiv.org/pdf/1601.06759)
7. Oord, Aaron van den, et al. Conditional image generation with PixelCNN decoders. (2016). [pdf](https://arxiv.org/pdf/1606.05328)

## 12 Image Captioning**

1. Farhadi,Ali,etal. **Every picture tells a story: Generating sentences from images**. 2010. [pdf](https://www.cs.cmu.edu/~afarhadi/papers/sentence.pdf) ️️️
2. Kulkarni, Girish, et al. **Baby talk: Understanding and generating image descriptions**. 2011. [pdf](http://tamaraberg.com/papers/generation_cvpr11.pdf)️️️️
3. Vinyals, Oriol, et al. **Show and tell: A neural image caption generator**. 2014. [pdf](https://arxiv.org/pdf/1411.4555.pdf)️️️
4. Donahue, Jeff, et al. **Long-term recurrent convolutional networks for visual recognition and description**. [pdf](https://arxiv.org/pdf/1411.4389.pdf)
5. Karpathy, Andrej, and Li Fei-Fei. **Deep visual-semantic alignments for generating image descriptions**. 2014. [pdf](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf)️️️️️
6. Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. **Deep fragment embeddings for bidirectional image sentence mapping**. 2014. [pdf](https://arxiv.org/pdf/1406.5679v1.pdf)️️️️
7. Fang, Hao, et al. **From captions to visual concepts and back**. 2014. [pdf](https://arxiv.org/pdf/1411.4952v3.pdf)️️️️️
8. Chen, Xinlei, and C. Lawrence Zitnick. **Learning a recurrent visual representation for image caption generation**. 2014. [pdf](https://arxiv.org/pdf/1411.5654v1.pdf)️️️️
9. Mao, Junhua, et al. **Deep captioning with multimodal recurrent neural networks** 2014. [pdf](https://arxiv.org/pdf/1412.6632v5.pdf)️️️
10. Xu, Kelvin, et al. **Show, attend and tell: Neural image caption generation with visual attention**. 2015. [pdf](https://arxiv.org/pdf/1502.03044v3.pdf)️️️


## 13 Speech Recognition

**\[10.0\]** Hinton, Geoffrey, et al. **Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups**. IEEE Signal Processing Magazine 29.6 (2012): 82-97. [\[](http://cs224d.stanford.edu/papers/maas_paper.pdf)[pdf\]](http://cs224d.stanford.edu/papers/maas_paper.pdf) **(****DeepNets show progress in speech recognition.)**️️️️
**\[10.1\]** Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. **Speech recognition with deep recurrent neural networks**. 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [\[](http://arxiv.org/pdf/1303.5778.pdf)[pdf\]](http://arxiv.org/pdf/1303.5778.pdf) **(RNN)**️️️
**\[10.2\]** Graves, Alex, and Navdeep Jaitly. **Towards End-To-End Speech Recognition with Recurrent Neural Networks**. ICML. Vol. 14. 2014. [\[](http://www.jmlr.org/proceedings/papers/v32/graves14.pdf)[pdf\]](http://www.jmlr.org/proceedings/papers/v32/graves14.pdf)️️️
**\[10.3\]** Sak, Haşim, et al. **Fast and accurate recurrent neural network acoustic models for speech recognition**. arXiv preprint arXiv:1507.06947 (2015). [\[](http://arxiv.org/pdf/1507.06947)[pdf\]](http://arxiv.org/pdf/1507.06947) **(****Google Speech Recognition System)** ️️️
**\[10.4\]** Amodei, Dario, et al. **Deep speech 2: End-to-end speech recognition in english and mandarin**. arXiv preprint arXiv:1512.02595 (2015). [\[](https://arxiv.org/pdf/1512.02595.pdf)[pdf\]](https://arxiv.org/pdf/1512.02595.pdf) **(****Baidu Speech Recognition System)** ️️️️
**\[10.5\]** W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig **Achieving Human Parity in Conversational Speech Recognition**. arXiv preprint arXiv:1610.05256 (2016). [\[](https://arxiv.org/pdf/1610.05256v1)[pdf\]](https://arxiv.org/pdf/1610.05256v1) **(****Microsoft Speech Recognition System)** ️️

## 14 Deep Learning Optimization and More

**\[12.0\]** Hinton, Geoffrey E., et al. **Improving neural networks by preventing co-adaptation of feature detectors**. arXiv preprint arXiv:1207.0580 (2012). [\[](https://arxiv.org/pdf/1207.0580.pdf)[pdf\]](https://arxiv.org/pdf/1207.0580.pdf) **(****Dropout)** ️️️
**\[12.1\]** Srivastava, Nitish, et al. **Dropout: a simple way to prevent neural networks from overfitting**. Journal of Machine Learning Research 15.1 (2014): 1929-1958. [\[](http://www.jmlr.org/papers/volume15/srivastava14a.old/source/srivastava14a.pdf)[pdf\]](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf) ️️️
**\[12.2\]** Ioffe, Sergey, and Christian Szegedy. **Batch normalization: Accelerating deep network training by reducing internal covariate shift**. arXiv preprint arXiv:1502.03167 (2015). [\[](http://arxiv.org/pdf/1502.03167)[pdf\]](http://arxiv.org/pdf/1502.03167) **(****An outstanding Work in 2015)** ️️️️
**\[12.3\]** Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. **Layer normalization**. arXiv preprint arXiv:1607.06450 (2016). [\[](https://arxiv.org/pdf/1607.06450.pdf?utm_source=sciontist.com&utm_medium=refer&utm_campaign=promote)[pdf\]](https://arxiv.org/pdf/1607.06450.pdf?utm_source=sciontist.com&utm_medium=refer&utm_campaign=promote) **(****Update of Batch Normalization)** ️
**\[12.4\]** Courbariaux, Matthieu, et al. **Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or−1**. [\[](https://pdfs.semanticscholar.org/f832/b16cb367802609d91d400085eb87d630212a.pdf)[pdf\]](https://pdfs.semanticscholar.org/f832/b16cb367802609d91d400085eb87d630212a.pdf) **(****New Model,Fast)**  ️️️
**\[12.5\]** Jaderberg, Max, et al. **Decoupled neural interfaces using synthetic gradients**. arXiv preprint arXiv:1608.05343 (2016). [\[](https://arxiv.org/pdf/1608.05343)[pdf\]](https://arxiv.org/pdf/1608.05343) **(****Innovation of Training Method,Amazing Work)** ️️
**\[12.6\]** Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. Net2net: Accelerating learning via knowledge transfer. arXiv preprint arXiv:1511.05641 (2015). [\[](https://arxiv.org/abs/1511.05641)[pdf\]](https://arxiv.org/abs/1511.05641) **(****Modify previously trained network to reduce training epochs)** ️️️
**\[12.7\]** Wei, Tao, et al. Network Morphism. arXiv preprint arXiv:1603.01670 (2016). [\[](https://arxiv.org/abs/1603.01670)[pdf\]](https://arxiv.org/abs/1603.01670) **(****Modify previously trained network to reduce training epochs)** ️️️
**\[12.8\]** Sutskever, Ilya, et al. **On the importance of initialization and momentum in deep learning**. ICML (3) 28 (2013): 1139-1147. [\[](http://www.jmlr.org/proceedings/papers/v28/sutskever13.pdf)[pdf\]](http://www.jmlr.org/proceedings/papers/v28/sutskever13.pdf) **(****Momentum optimizer)** ️️
**\[12.9\]** Kingma, Diederik, and Jimmy Ba. **Adam: A method for stochastic optimization**. arXiv preprint arXiv:1412.6980 (2014). [\[](http://arxiv.org/pdf/1412.6980)[pdf\]](http://arxiv.org/pdf/1412.6980) **(****Maybe used most often currently)** ️
**\[12.10\]** Andrychowicz, Marcin, et al. **Learning to learn by gradient descent by gradient descent**. arXiv preprint arXiv:1606.04474 (2016). [\[](https://arxiv.org/pdf/1606.04474)[pdf\]](https://arxiv.org/pdf/1606.04474) **(****Neural Optimizer, Amazing Work)** ️️️️️
**\[12.11\]** Han, Song, Huizi Mao, and William J. Dally. **Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding**. CoRR, abs/1510.00149 2 (2015). [\[](https://pdfs.semanticscholar.org/5b6c/9dda1d88095fa4aac1507348e498a1f2e863.pdf)[pdf\]](https://pdfs.semanticscholar.org/5b6c/9dda1d88095fa4aac1507348e498a1f2e863.pdf) **(****ICLR best paper, new direction to make NN running fast, DeePhi Tech Startup)** ️️️️️
**\[12.12\]** Iandola, Forrest N., et al. **SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size**. arXiv preprint arXiv:1602.07360 (2016). [\[](http://arxiv.org/pdf/1602.07360)[pdf\]](http://arxiv.org/pdf/1602.07360) **(****Also a new direction to optimize NN,DeePhi Tech Startup)** ️️️️

## 15 Robotics

****
**\[14.0\]** Koutník, Jan, et al. **Evolving large-scale neural networks for vision-based reinforcement learning**. Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [\[](http://repository.supsi.ch/4550/1/koutnik2013gecco.pdf)[pdf\]](http://repository.supsi.ch/4550/1/koutnik2013gecco.pdf) ️️️
**\[14.1\]** Levine, Sergey, et al. **End-to-end training of deep visuomotor policies**. Journal of Machine Learning Research 17.39 (2016): 1-40. [\[](http://www.jmlr.org/papers/volume17/15-522/15-522.pdf)[pdf\]](http://www.jmlr.org/papers/volume17/15-522/15-522.pdf) ️️️️️
**\[14.2\]** Pinto, Lerrel, and Abhinav Gupta. **Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours**. arXiv preprint arXiv:1509.06825 (2015). [\[](http://arxiv.org/pdf/1509.06825)[pdf\]](http://arxiv.org/pdf/1509.06825) ️️️
**\[14.3\]** Levine, Sergey, et al. **Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection**. arXiv preprint arXiv:1603.02199 (2016). [\[](http://arxiv.org/pdf/1603.02199)[pdf\]](http://arxiv.org/pdf/1603.02199) ️️️️
**\[14.4\]** Zhu, Yuke, et al. **Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning**. arXiv preprint arXiv:1609.05143 (2016). [\[](https://arxiv.org/pdf/1609.05143)[pdf\]](https://arxiv.org/pdf/1609.05143) ️️️️
**\[14.5\]** Yahya, Ali, et al. **Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search**. arXiv preprint arXiv:1610.00673 (2016). [\[](https://arxiv.org/pdf/1610.00673)[pdf\]](https://arxiv.org/pdf/1610.00673) ️️️️
**\[14.6\]** Gu, Shixiang, et al. **Deep Reinforcement Learning for Robotic Manipulation**. arXiv preprint arXiv:1610.00633 (2016). [\[](https://arxiv.org/pdf/1610.00633)[pdf\]](https://arxiv.org/pdf/1610.00633) ️️️️
**\[14.7\]** A Rusu, M Vecerik, Thomas Rothörl, N Heess, R Pascanu, R Hadsell.**Sim-to-Real Robot Learning from Pixels with Progressive Nets**. arXiv preprint arXiv:1610.04286 (2016). [\[](https://arxiv.org/pdf/1610.04286.pdf)[pdf\]](https://arxiv.org/pdf/1610.04286.pdf) ️️️️
**\[14.8\]** Mirowski, Piotr, et al. **Learning to navigate in complex environments**. arXiv preprint arXiv:1611.03673 (2016). [\[](https://arxiv.org/pdf/1611.03673)[pdf\]](https://arxiv.org/pdf/1611.03673)️️️️

## 16 Deep Transfer Learning / Lifelong Learning / especially for RL

**\[15.0\]** Bengio, Yoshua. **Deep Learning of Representations for Unsupervised and Transfer Learning**. ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [\[](http://www.jmlr.org/proceedings/papers/v27/bengio12a/bengio12a.pdf)[pdf\]](http://www.jmlr.org/proceedings/papers/v27/bengio12a/bengio12a.pdf) **(****A Tutorial)** ️️️
**\[15.1\]** Silver, Daniel L., Qiang Yang, and Lianghao Li. **Lifelong Machine Learning Systems: Beyond Learning Algorithms**. AAAI Spring Symposium: Lifelong Machine Learning. 2013. [\[](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.696.7800&rep=rep1&type=pdf)[pdf\]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.696.7800&rep=rep1&type=pdf) **(****A brief discussion about lifelong learning)**  ️️️
**\[15.2\]** Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. **Distilling the knowledge in a neural network**. arXiv preprint arXiv:1503.02531 (2015). [\[](http://arxiv.org/pdf/1503.02531)[pdf\]](http://arxiv.org/pdf/1503.02531) **(****Godfather's Work)** ️️️️
**\[15.3\]** Rusu, Andrei A., et al. **Policy distillation**. arXiv preprint arXiv:1511.06295 (2015). [\[](http://arxiv.org/pdf/1511.06295)[pdf\]](http://arxiv.org/pdf/1511.06295) **(****RL domain)** ️️️
**\[15.4\]** Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. **Actor-mimic: Deep multitask and transfer reinforcement learning**. arXiv preprint arXiv:1511.06342 (2015). [\[](http://arxiv.org/pdf/1511.06342)[pdf\]](http://arxiv.org/pdf/1511.06342) **(****RL domain)** ️️️
**\[15.5\]** Rusu, Andrei A., et al. **Progressive neural networks**. arXiv preprint arXiv:1606.04671 (2016). [\[](https://arxiv.org/pdf/1606.04671)[pdf\]](https://arxiv.org/pdf/1606.04671) **(****Outstanding Work, A novel idea)** ️️️️️

## 17 One Shot Deep Learning

**\[16.0\]** Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. **Human-level concept learning through probabilistic program induction**. Science 350.6266 (2015): 1332-1338. [\[](http://clm.utexas.edu/compjclub/wp-content/uploads/2016/02/lake2015.pdf)[pdf\]](http://clm.utexas.edu/compjclub/wp-content/uploads/2016/02/lake2015.pdf) **(****No Deep Learning, but worth reading)**️️️️️
**\[16.1\]** Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. **Siamese Neural Networks for One-shot Image Recognition**.(2015) [\[](http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf)[pdf\]](http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf) ️️️
**\[16.2\]** Santoro, Adam, et al. **One-shot Learning with Memory-Augmented Neural Networks**. arXiv preprint arXiv:1605.06065 (2016). [\[](http://arxiv.org/pdf/1605.06065)[pdf\]](http://arxiv.org/pdf/1605.06065) **(****A basic step to one shot learning)** ️️️️
**\[16.3\]** Vinyals, Oriol, et al. **Matching Networks for One Shot Learning**. arXiv preprint arXiv:1606.04080 (2016). [\[](https://arxiv.org/pdf/1606.04080)[pdf\]](https://arxiv.org/pdf/1606.04080)️️️
**\[16.4\]** Hariharan, Bharath, and Ross Girshick. **Low-shot visual object recognition**. arXiv preprint arXiv:1606.02819 (2016). [\[](http://arxiv.org/pdf/1606.02819)[pdf\]](http://arxiv.org/pdf/1606.02819) **(****A step to large data)** ️️️️

## 18 Neural Turing Machine

**\[17.0\]** Graves, Alex, Greg Wayne, and Ivo Danihelka. **Neural turing machines**. arXiv preprint arXiv:1410.5401 (2014). [\[](http://arxiv.org/pdf/1410.5401.pdf)[pdf\]](http://arxiv.org/pdf/1410.5401.pdf) **(Basic Prototype of Future Computer)** ️️️️️
**\[17.1\]** Zaremba, Wojciech, and Ilya Sutskever. **Reinforcement learning neural Turing machines**. arXiv preprint arXiv:1505.00521 362 (2015). [\[](https://pdfs.semanticscholar.org/f10e/071292d593fef939e6ef4a59baf0bb3a6c2b.pdf)[pdf\]](https://pdfs.semanticscholar.org/f10e/071292d593fef939e6ef4a59baf0bb3a6c2b.pdf) ️️️
**\[17.2\]** Weston, Jason, Sumit Chopra, and Antoine Bordes. **Memory networks**. arXiv preprint arXiv:1410.3916 (2014). [\[](http://arxiv.org/pdf/1410.3916)[pdf\]](http://arxiv.org/pdf/1410.3916)️️️
**\[17.3\]** Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. **End-to-end memory networks**. Advances in neural information processing systems. 2015. [\[](http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf)[pdf\]](http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf) ️️️️
**\[17.4\]** Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. **Pointer networks**. Advances in Neural Information Processing Systems. 2015. [\[](http://papers.nips.cc/paper/5866-pointer-networks.pdf)[pdf\]](http://papers.nips.cc/paper/5866-pointer-networks.pdf) ️️️️
**\[17.5\]** Graves, Alex, et al. **Hybrid computing using a neural network with dynamic external memory**. Nature (2016). [\[](https://www.dropbox.com/s/0a40xi702grx3dq/2016-graves.pdf)[pdf\]](https://www.dropbox.com/s/0a40xi702grx3dq/2016-graves.pdf)  ️️️️️

credit [Prof. Peter N Belhumeur](https://www.advancedtopicsindeeplearning.com/)
